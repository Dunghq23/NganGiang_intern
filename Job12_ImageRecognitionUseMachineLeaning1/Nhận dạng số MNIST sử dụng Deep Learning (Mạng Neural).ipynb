{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOSMGH8bcDdYg4xYfPbdKAe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**Nhận dạng số MNIST bằng cách sử dụng Deep Learning (Mạng Neural)**\n","\n","Phân lớp Softmax được xử lý trong một lớp, nhưng mạng lưới Neural sử dụng n lớp, thường được gọi là học sâu - Deep Learning. Nhiều lớp sử dụng một số W (Weight – trọng lượng, trọng số) và b (bias – độ lệch) thay vì một W và một b.\n","Trong mạng Neural, có một quy tắc phải được tuân theo bởi số lượng dữ liệu đầu vào và dữ liệu đầu ra. Ví dụ: nếu sử dụng 784 pixel dữ liệu làm đầu vào đầu tiên và nhận 10 dữ liệu số từ 0 đến 9 làm đầu ra cuối cùng, nếu đặt 256 dữ liệu đầu ra ở lớp giữa, thì nên nhập vào 256 dữ liệu đầu vào ở lớp tiếp theo. Có thể kiểm tra Weight của mã nguồn chương trình sau.\n"],"metadata":{"id":"hN26lCfU1xcA"}},{"cell_type":"markdown","source":["## Đầu tiên ta cần nhập các thư viện sau:\n","\n","1.   **tensorflow**: Sử dụng các tính năng và lớp của TensorFlow.\n","1.   **random**: Sử dụng các hàm liên quan đến số ngẫu nhiên.\n","2.   **matplotlib.pyplot**: Vẽ đồ thị và hiển thị hình ảnh.\n","3.   **mnist**: Dữ liệu từ bộ dữ liệu MNIST từ tensorflow.keras.datasets. Bộ dữ liệu MNIST là một bộ dữ liệu chứa các hình ảnh kích thước 28x28 của các chữ số viết tay từ 0 đến 9."],"metadata":{"id":"7unJz1B-2KOQ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"q_PWn5vF1hv3","executionInfo":{"status":"ok","timestamp":1700035499445,"user_tz":-420,"elapsed":3341,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"outputs":[],"source":["import tensorflow as tf\n","import random\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.datasets import mnist"]},{"cell_type":"markdown","source":["## Thiết lập seed cho tính ngẫu nhiên để có thể tái tạo kết quả\n","1.   **Seed là gì?**\n","\n","  Seed là một giá trị số nguyên dùng để khởi tạo quy luật sinh số ngẫu nhiên, đảm bảo tính nhất quán trong quá trình thử nghiệm.\n","\n","2.   **Tại sao cần Seed?**\n","\n","  *   Tránh sự thay đổi ngẫu nhiên mỗi lần chạy mã.\n","  *   Tái tạo kết quả và kiểm soát thử nghiệm.\n","\n","3.   **Cách Sử Dụng Seed trong TensorFlow**\n","\n","  `tf.random.set_seed(777)`\n","\n","  Chọn seed phù hợp với mục đích của bạn.\n","4.   **Kết Quả Tái Tạo**\n","\n","  Seed giúp tái tạo kết quả mỗi lần chạy mã.\n","5.   **Không Đặt Seed**\n","\n","  TensorFlow sẽ sử dụng seed mặc định hoặc giá trị ngẫu nhiên, dẫn đến kết quả không nhất quán.\n","6.   Quan Trọng trong Đào Tạo Mô Hình\n","\n","  Kiểm soát số ngẫu nhiên giúp đảm bảo công bằng và nhất quán trong thử nghiệm và so sánh mô hình.\n"],"metadata":{"id":"w0ycpjq-3TcH"}},{"cell_type":"code","source":["tf.random.set_seed(777)"],"metadata":{"id":"X9dRFXl_3TOn","executionInfo":{"status":"ok","timestamp":1700035499446,"user_tz":-420,"elapsed":9,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Tải dữ liệu MNIST từ thư viện Keras\n","\n","Trước hết cần tải dữ liệu từ bộ dữ liệu MNIST trong TensorFlow thông qua **mnist.load_data()**. Bộ dữ liệu MNIST là một tập dữ liệu phổ biến trong lĩnh vực học máy, được sử dụng để huấn luyện và kiểm thử mô hình trong bài toán nhận diện chữ số viết tay từ 0 đến 9.\n","\n","*   **(x_train, y_train)**: *Là dữ liệu huấn luyện, trong đó x_train là các hình ảnh của các chữ số và y_train là nhãn tương ứng của chúng (chứa các giá trị từ 0 đến 9).*\n","\n","*   **(x_test, y_test)**: *Là dữ liệu kiểm thử, tương tự như dữ liệu huấn luyện, nhưng được sử dụng để kiểm tra hiệu suất của mô hình sau khi đã được huấn luyện.*\n","\n","Dòng mã dưới đây giúp bạn nhanh chóng nạp dữ liệu MNIST vào các biến x_train, y_train, x_test, và y_test để sử dụng chúng trong quá trình đào tạo và kiểm thử mô hình."],"metadata":{"id":"UMOdrqcV3qMf"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"metadata":{"id":"xL9NQx8E3pog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700035501075,"user_tz":-420,"elapsed":1636,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}},"outputId":"ca44bf14-0f5e-48ed-b580-8ba8927d1207"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"markdown","source":["## Chuẩn hóa giá trị pixel về khoảng [0, 1]\n","Chúng ta cần thực hiện việc chuẩn hóa dữ liệu hình ảnh trong bộ dữ liệu MNIST. Cụ thể, nó chia giá trị của mỗi pixel trong hình ảnh cho 255.0. Quy trình này được thực hiện để đưa các giá trị pixel về khoảng từ 0 đến 1.\n","\n","Bởi vì giá trị pixel thường nằm trong khoảng từ 0 đến 255 (với 0 là đen và 255 là trắng), việc chuẩn hóa giúp mô hình học máy hội tụ nhanh hơn và có khả năng tổng quát hóa tốt hơn trên dữ liệu mới.\n","\n","Chuẩn hóa giá trị pixel giúp giảm biên độ của đặc trưng và đồng thời làm cho mô hình dễ dàng học từ dữ liệu. Nó là một phương pháp chuẩn xác và thường được áp dụng khi xử lý dữ liệu hình ảnh trong các bài toán học máy.\n","\n","```\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","```\n","\n"],"metadata":{"id":"3DRHcnJ73S_v"}},{"cell_type":"code","source":["x_train, x_test = x_train / 255.0, x_test / 255.0"],"metadata":{"id":"9wJhZ3wS-Obf","executionInfo":{"status":"ok","timestamp":1700035501075,"user_tz":-420,"elapsed":9,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Khai báo các tham số cơ bản cho quá trình đào tạo mô hình.\n","\n","1.   **learning_rate**: Là tỷ lệ học, xác định bước nhảy trong quá trình cập nhật trọng số của mô hình dựa trên độ dốc của hàm mất mát. Một learning rate nhỏ có thể làm cho mô hình hội tụ chậm, trong khi một learning rate lớn có thể làm cho quá trình hội tụ không ổn định.\n","\n","2.   **training_epochs**: Là số lần lặp qua toàn bộ tập dữ liệu huấn luyện trong quá trình đào tạo. Mỗi lần lặp gọi là một epoch. Số epoch quyết định số lần mô hình được huấn luyện trên toàn bộ dữ liệu.\n","\n","3.   **batch_size**: Là kích thước của từng batch (phần nhỏ) dữ liệu được sử dụng để cập nhật trọng số trong mỗi lần lặp (epoch). Việc sử dụng mini-batch giúp giảm bộ nhớ được yêu cầu và tăng tốc quá trình đào tạo, đặc biệt là khi làm việc với dữ liệu lớn. Giá trị thường được chọn là một số nguyên dương, chẳng hạn như 32, 64, hoặc 128."],"metadata":{"id":"kcrZot1h-OHf"}},{"cell_type":"code","source":["learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100"],"metadata":{"id":"tfIpzQZtBfQ_","executionInfo":{"status":"ok","timestamp":1700035501075,"user_tz":-420,"elapsed":8,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Tắt tính toán tự động (eager execution) trong TensorFlow.\n","\n","**Eager execution** là một tính năng trong TensorFlow 2.x giúp thực hiện tính toán ngay lập tức và giúp việc debug và thử nghiệm trở nên linh hoạt hơn. Tuy nhiên, trong một số trường hợp, nhất là khi sử dụng TensorFlow 1.x, việc tắt eager execution là cần thiết.\n","\n","Việc tắt eager execution chuyển TensorFlow về chế độ \"**graph mode**\", nơi tính toán được xây dựng và tối ưu hóa trước khi thực thi. Điều này có thể hữu ích khi bạn đang xây dựng các mô hình lớn và muốn kiểm soát quá trình tính toán một cách chặt chẽ hơn."],"metadata":{"id":"4ns8HPp0DcK3"}},{"cell_type":"code","source":["tf.compat.v1.disable_eager_execution()"],"metadata":{"id":"TmKnOZ0gDcEm","executionInfo":{"status":"ok","timestamp":1700035501075,"user_tz":-420,"elapsed":8,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Tạo hai placeholder trong TensorFlow để đại diện cho dữ liệu đầu vào trong mô hình.\n","**X: Là một placeholder được tạo để chứa dữ liệu đầu vào của mô hình. Được định hình với kiểu dữ liệu là tf.float32 và kích thước là [None, 784].**\n","*   None ở đây có nghĩa là số lượng mẫu có thể thay đổi, tùy thuộc vào batch size bạn đưa vào trong quá trình đào tạo hoặc kiểm thử mô hình.\n","*   784 là số chiều của mỗi mẫu dữ liệu đầu vào. Trong trường hợp này, có thể nghĩ đến đây là số lượng pixel trong mỗi hình ảnh (28x28 pixel) được làm phẳng thành một vector có kích thước 784.\n","\n","**Y: Là một placeholder được tạo để chứa nhãn tương ứng với dữ liệu đầu vào. Được định hình với kiểu dữ liệu là tf.float32 và kích thước là [None, 10].**\n","\n","  *   None ở đây cũng có ý nghĩa giống như ở placeholder X, có thể thay đổi tùy thuộc vào batch size.\n","  *  10 là số lượng lớp, và mỗi mẫu dữ liệu sẽ được biểu diễn bằng một vector one-hot encoding với 10 phần tử. Điều này phản ánh rằng mô hình sẽ đưa ra dự đoán về xác suất cho mỗi lớp (tổng cộng là 10 lớp)."],"metadata":{"id":"z7AEf8SMDb-_"}},{"cell_type":"code","source":["X = tf.compat.v1.placeholder(tf.float32, [None, 784])\n","Y = tf.compat.v1.placeholder(tf.float32, [None, 10])"],"metadata":{"id":"qS3DyzpFDb4g","executionInfo":{"status":"ok","timestamp":1700035501076,"user_tz":-420,"elapsed":8,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Xây dựng một mô hình neural network (mạng nơ-ron) với ba tầng (layer).\n","**Mô hình này có ba tầng tuyến tính và hai hàm kích hoạt ReLU (Rectified Linear Unit).**\n","\n","1. **Tạo các biến trọng số và bias cho từng tầng:**\n","   - `W1`, `W2`, `W3`: Là các ma trận trọng số cho tầng thứ nhất, thứ hai và thứ ba tương ứng.\n","   - `b1`, `b2`, `b3`: Là các vector bias tương ứng với từng tầng.\n","\n","   Mỗi ma trận trọng số có kích thước [số đầu vào, số đầu ra]. Cụ thể ở đây, `W1` có kích thước [784, 256], `W2` có kích thước [256, 256], và `W3` có kích thước [256, 10]. Các vector bias có số chiều tương ứng với số đầu ra của từng tầng.\n","\n","2. **Xây dựng các tầng của mạng nơ-ron:**\n","   - `L1`: Tầng thứ nhất với hàm kích hoạt ReLU (`tf.nn.relu`). Đầu vào của tầng này là `X` (đầu vào của mô hình), và đầu ra là kết quả của phép nhân ma trận giữa `X` và `W1`, sau đó cộng thêm vector bias `b1` và áp dụng hàm kích hoạt ReLU.\n","   - `L2`: Tầng thứ hai tương tự như tầng thứ nhất. Đầu vào của tầng này là đầu ra của tầng thứ nhất (`L1`), và đầu ra là kết quả của phép nhân ma trận giữa `L1` và `W2`, sau đó cộng thêm vector bias `b2` và áp dụng hàm kích hoạt ReLU.\n","   - `hypothesis`: Tầng cuối cùng, không sử dụng hàm kích hoạt, với đầu vào là đầu ra của tầng thứ hai (`L2`). Kết quả của phép nhân ma trận giữa `L2` và `W3`, sau đó cộng thêm vector bias `b3`.\n","\n","Các phép toán này thường được sử dụng trong quá trình feedforward của mạng nơ-ron để tạo ra dự đoán từ đầu vào. Các trọng số (`W1`, `W2`, `W3`) và bias (`b1`, `b2`, `b3`) sẽ được điều chỉnh trong quá trình huấn luyện mô hình để giảm sai số giữa dự đoán và giá trị thực tế."],"metadata":{"id":"sKKOK9eGDbyn"}},{"cell_type":"code","source":["W1 = tf.Variable(tf.compat.v1.random_normal([784, 256]))\n","b1 = tf.Variable(tf.compat.v1.random_normal([256]))\n","L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n","\n","W2 = tf.Variable(tf.compat.v1.random_normal([256, 256]))\n","b2 = tf.Variable(tf.compat.v1.random_normal([256]))\n","L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n","\n","W3 = tf.Variable(tf.compat.v1.random_normal([256, 10]))\n","b3 = tf.Variable(tf.compat.v1.random_normal([10]))\n","hypothesis = tf.matmul(L2, W3) + b3"],"metadata":{"id":"fA5bnRhkDbr_","executionInfo":{"status":"ok","timestamp":1700035501076,"user_tz":-420,"elapsed":8,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Định nghĩa hàm chi phí (cost/loss) và bộ tối ưu hóa (optimizer) để huấn luyện mô hình\n","\n","1. **Hàm chi phí (Cost/Loss):**  \n","   - `tf.nn.softmax_cross_entropy_with_logits`: Đây là hàm chi phí sử dụng trong bài toán phân loại nhiều lớp khi đầu ra của mô hình được áp dụng hàm softmax (đối với `hypothesis`). Hàm này tính toán sự chênh lệch giữa phân phối xác suất dự đoán (`hypothesis`) và phân phối xác suất thực tế (`Y`), sau đó tính giá trị trung bình của các sự chênh lệch này trên toàn bộ dữ liệu.\n","   - `tf.reduce_mean`: Là hàm tính giá trị trung bình của các phần tử trong ma trận. Nó giúp chuyển từ chi phí tổng cộng sang chi phí trung bình trên mỗi mẫu dữ liệu.\n","\n","2. **Bộ tối ưu hóa (Optimizer):**\n","   - `tf.compat.v1.train.GradientDescentOptimizer`: Đây là một trình tối ưu hóa sử dụng thuật toán gradient descent để điều chỉnh trọng số và bias của mô hình để giảm chi phí. `learning_rate` là một siêu tham số quan trọng trong thuật toán này, xác định kích thước của bước cập nhật trong không gian trọng số. Nó quyết định tốc độ học của mô hình - nếu quá lớn, có thể bị vượt quá điểm tối ưu; nếu quá nhỏ, quá trình học sẽ diễn ra rất chậm.\n","   - `minimize(cost)`: Là phương thức của optimizer, được sử dụng để tối ưu hóa hàm chi phí. Nó sẽ thực hiện quá trình lan truyền ngược (backpropagation) để tính gradient của hàm chi phí đối với các tham số (trọng số và bias), sau đó áp dụng gradient descent để cập nhật các tham số và giảm chi phí.\n","\n","Tóm lại, qua mỗi lượt huấn luyện, trọng số và bias của mô hình sẽ được cập nhật dựa trên đạo hàm của hàm chi phí, và quá trình này sẽ được thực hiện với mỗi mini-batch của dữ liệu đào tạo để cải thiện hiệu suất của mô hình."],"metadata":{"id":"Id5hlMclDbl-"}},{"cell_type":"code","source":["cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n","  logits=hypothesis, labels=Y\n","))\n","optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"],"metadata":{"id":"5EwTI5ciDbd-","executionInfo":{"status":"ok","timestamp":1700035502178,"user_tz":-420,"elapsed":1108,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Khởi tạo một phiên (session) của TensorFlow và khởi tạo tất cả các biến (trọng số và bias) trong mô hình.\n","\n","1. **Khởi tạo phiên TensorFlow:**\n","   - `tf.compat.v1.Session()`: Tạo một phiên TensorFlow. Phiên này sẽ được sử dụng để thực hiện các phép toán trong đồ thị tính toán của TensorFlow.\n","\n","2. **Khởi tạo tất cả các biến:**\n","   - `tf.compat.v1.global_variables_initializer()`: Tạo một hoạt động (operation) để khởi tạo tất cả các biến trong đồ thị tính toán. Biến là các tham số (trọng số và bias) trong mô hình, và trước khi bắt đầu quá trình huấn luyện, chúng ta cần khởi tạo chúng với các giá trị ban đầu.\n","\n","   - `sess.run(tf.compat.v1.global_variables_initializer())`: Chạy hoạt động khởi tạo trong phiên TensorFlow. Sau dòng mã này, tất cả các biến trong mô hình đã được khởi tạo với giá trị ngẫu nhiên (được tạo trong các lớp trọng số và bias) và sẵn sàng để bắt đầu quá trình huấn luyện.\n","\n","Điều này là quan trọng vì trước khi huấn luyện mô hình, chúng ta cần có các giá trị khởi tạo cho trọng số và bias để bắt đầu quá trình học từ."],"metadata":{"id":"XbGdr_NcDbPH"}},{"cell_type":"code","source":["sess = tf.compat.v1.Session()\n","sess.run(tf.compat.v1.global_variables_initializer())"],"metadata":{"id":"4C1TBZdJDa9I","executionInfo":{"status":"ok","timestamp":1700035504121,"user_tz":-420,"elapsed":1946,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Huấn luyện mô hình:\n","\n","### 1. Vòng lặp Huấn luyện:\n","\n","```python\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","    total_batch = int(len(x_train) / batch_size)\n","```\n","\n","- `for epoch in range(training_epochs):`: Bắt đầu vòng lặp qua các epoch (lượt huấn luyện). Mỗi epoch đại diện cho một lượt đưa toàn bộ tập dữ liệu qua mô hình.\n","\n","- `avg_cost = 0`: Khởi tạo giá trị trung bình của chi phí để theo dõi sự thay đổi của chi phí trong suốt quá trình huấn luyện.\n","\n","- `total_batch = int(len(x_train) / batch_size)`: Tính tổng số mini-batch trong mỗi epoch. `batch_size` là kích thước của từng mini-batch, và `len(x_train)` là số lượng mẫu trong tập huấn luyện.\n","\n","### 2. Vòng lặp qua Mini-batch:\n","\n","```python\n","    for i in range(total_batch):\n","        start = i * batch_size\n","        end = (i + 1) * batch_size\n","        batch_xs, batch_ys = x_train[start:end], y_train[start:end]\n","        batch_xs = batch_xs.reshape(-1, 784)\n","        batch_ys = tf.keras.utils.to_categorical(batch_ys, 10)\n","        feed_dict = {X: batch_xs, Y: batch_ys}\n","        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n","        avg_cost += c / total_batch\n","```\n","\n","- `for i in range(total_batch):`: Bắt đầu vòng lặp qua từng mini-batch trong mỗi epoch.\n","\n","- `start = i * batch_size`, `end = (i + 1) * batch_size`: Xác định đoạn của tập huấn luyện mà mini-batch đang xử lý.\n","\n","- `batch_xs, batch_ys = x_train[start:end], y_train[start:end]`: Lấy ra các mẫu và nhãn của mini-batch hiện tại từ tập huấn luyện.\n","\n","- `batch_xs = batch_xs.reshape(-1, 784)`: Reshape ma trận dữ liệu đầu vào của mỗi mini-batch về kích thước [số lượng mẫu, số lượng đặc trưng] (ở đây là [batch_size, 784]).\n","\n","- `batch_ys = tf.keras.utils.to_categorical(batch_ys, 10)`: Chuyển đổi nhãn về dạng one-hot encoding vì hàm chi phí `tf.nn.softmax_cross_entropy_with_logits` mong đợi nhãn ở dạng này.\n","\n","- `feed_dict = {X: batch_xs, Y: batch_ys}`: Tạo một feed dictionary để cung cấp dữ liệu vào các placeholder `X` và `Y` trong đồ thị tính toán.\n","\n","- `c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)`: Chạy một lượt lan truyền và lan truyền ngược trên mini-batch hiện tại. `c` là giá trị chi phí của mini-batch, và `_` chỉ đơn giản là một biến giả mà chúng ta không quan tâm (được sử dụng để chạy optimizer).\n","\n","- `avg_cost += c / total_batch`: Cập nhật giá trị trung bình của chi phí cho epoch hiện tại.\n","\n","### 3. In thông tin sau mỗi epoch:\n","\n","```python\n","    print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n","```\n","\n","- In ra giá trị trung bình của chi phí sau mỗi epoch.\n","\n","### 4. Kết thúc quá trình huấn luyện:\n","\n","```python\n","print('Learning Finished')\n","```\n","\n","- In ra thông báo khi quá trình huấn luyện kết thúc.\n","\n","Toàn bộ quá trình này được thực hiện để điều chỉnh trọng số và bias của mô hình sao cho chi phí trung bình giảm qua mỗi epoch, từ đó cải thiện khả năng dự đoán của mô hình trên tập huấn luyện."],"metadata":{"id":"FEyi9CAmDauX"}},{"cell_type":"code","source":["for epoch in range(training_epochs):\n","    avg_cost = 0\n","    total_batch = int(len(x_train) / batch_size)\n","\n","    for i in range(total_batch):\n","        start = i * batch_size\n","        end = (i + 1) * batch_size\n","        batch_xs, batch_ys = x_train[start:end], y_train[start:end]\n","        batch_xs = batch_xs.reshape(-1, 784)\n","        batch_ys = tf.keras.utils.to_categorical(batch_ys, 10)\n","        feed_dict = {X: batch_xs, Y: batch_ys}\n","        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n","        avg_cost += c / total_batch\n","\n","    print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n","\n","print('Learning Finished')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEHEmdO52XX2","executionInfo":{"status":"ok","timestamp":1700035524245,"user_tz":-420,"elapsed":20126,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}},"outputId":"32638936-2746-44db-b82c-871ee22a1a6a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0001 cost =  155.467885487\n","Epoch: 0002 cost =  58.857990342\n","Epoch: 0003 cost =  43.462381841\n","Epoch: 0004 cost =  35.099588726\n","Epoch: 0005 cost =  29.537680197\n","Epoch: 0006 cost =  25.561045629\n","Epoch: 0007 cost =  22.645365008\n","Epoch: 0008 cost =  20.317035378\n","Epoch: 0009 cost =  18.432497804\n","Epoch: 0010 cost =  16.832576158\n","Epoch: 0011 cost =  15.496460258\n","Epoch: 0012 cost =  14.327235793\n","Epoch: 0013 cost =  13.306521504\n","Epoch: 0014 cost =  12.444058902\n","Epoch: 0015 cost =  11.665969313\n","Learning Finished\n"]}]},{"cell_type":"markdown","source":["## Kiểm thử mô hình và đánh giá độ chính xác trên tập kiểm thử. Dưới đây là giải thích từng phần:\n","\n","1. **Dự đoán đúng (Correct Prediction):**\n","   ```python\n","   correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n","   ```\n","   - `tf.argmax(hypothesis, 1)`: Tìm ra index của giá trị lớn nhất trong vector dự đoán `hypothesis` trên mỗi mẫu dữ liệu.\n","   - `tf.argmax(Y, 1)`: Tìm ra index của giá trị lớn nhất trong vector nhãn thực tế `Y` trên mỗi mẫu dữ liệu.\n","   - `tf.equal`: So sánh hai vector index, trả về một vector boolean, với `True` nếu dự đoán đúng và `False` nếu dự đoán sai.\n","\n","2. **Độ chính xác (Accuracy):**\n","   ```python\n","   accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","   ```\n","   - `tf.cast(correct_prediction, tf.float32)`: Chuyển đổi vector boolean thành vector số thực (1.0 cho `True` và 0.0 cho `False`).\n","   - `tf.reduce_mean`: Tính giá trị trung bình của vector số thực, cho ta tỉ lệ dự đoán đúng trên toàn bộ tập kiểm thử.\n","\n","3. **In ra độ chính xác:**\n","   ```python\n","   print('Accuracy:', sess.run(accuracy, feed_dict={\n","       X: x_test.reshape(-1, 784),\n","       Y: tf.keras.utils.to_categorical(y_test, 10)\n","   }))\n","   ```\n","   - `sess.run(accuracy, feed_dict={...})`: Chạy đồ thị tính toán để tính toán độ chính xác trên tập kiểm thử.\n","   - `X: x_test.reshape(-1, 784)`: Feed giá trị đầu vào kiểm thử vào placeholder `X`.\n","   - `Y: tf.keras.utils.to_categorical(y_test, 10)`: Chuyển đổi nhãn kiểm thử về dạng one-hot encoding và feed vào placeholder `Y`.\n","\n","Cuối cùng, dòng mã này in ra độ chính xác của mô hình trên tập kiểm thử. Độ chính xác được tính bằng cách so sánh dự đoán của mô hình với nhãn thực tế và tính tỉ lệ dự đoán đúng trên toàn bộ tập kiểm thử."],"metadata":{"id":"FcmVgpui7rS9"}},{"cell_type":"code","source":["correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","print('Accuracy:', sess.run(accuracy, feed_dict={\n","    X: x_test.reshape(-1, 784),\n","    Y: tf.keras.utils.to_categorical(y_test, 10)\n","}))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6NbVr13-UOu","executionInfo":{"status":"ok","timestamp":1700035524245,"user_tz":-420,"elapsed":23,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}},"outputId":"4e62c4f1-b8e3-4367-f951-0ccf3546a81f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9078\n"]}]},{"cell_type":"markdown","source":["## Chọn một mẫu ngẫu nhiên từ tập kiểm thử, dự đoán nhãn của mẫu đó bằng mô hình, và hiển thị hình ảnh cùng với nhãn thực tế và dự đoán.\n","\n","1. **Chọn mẫu ngẫu nhiên từ tập kiểm thử:**\n","   ```python\n","   r = random.randint(0, len(x_test) - 1)\n","   ```\n","   - `random.randint(0, len(x_test) - 1)`: Tạo một số ngẫu nhiên là index của một mẫu trong tập kiểm thử.\n","\n","2. **In ra nhãn thực tế của mẫu đã chọn:**\n","   ```python\n","   print(\"Label:\", y_test[r])\n","   ```\n","   - In ra nhãn thực tế của mẫu đã chọn.\n","\n","3. **Dự đoán nhãn bằng mô hình:**\n","   ```python\n","   print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: x_test[r].reshape(1, -1)}))\n","   ```\n","   - `sess.run(tf.argmax(hypothesis, 1), feed_dict={X: x_test[r].reshape(1, -1)})`: Chạy đồ thị tính toán để dự đoán nhãn của mẫu đã chọn bằng mô hình. `tf.argmax(hypothesis, 1)` trả về index của giá trị lớn nhất trong vector dự đoán.\n","\n","4. **Hiển thị hình ảnh của mẫu đã chọn:**\n","   ```python\n","   plt.imshow(x_test[r], cmap=\"hot\")\n","   plt.show()\n","   ```\n","   - `plt.imshow(x_test[r], cmap=\"hot\")`: Hiển thị hình ảnh của mẫu đã chọn sử dụng thư viện Matplotlib.\n","   - `plt.show()`: Hiển thị hình ảnh trong cửa sổ đồ họa.\n","\n","Dòng mã này giúp bạn có cái nhìn trực quan về cách mô hình dự đoán trên một mẫu cụ thể từ tập kiểm thử."],"metadata":{"id":"d94Ua9XW-TPy"}},{"cell_type":"code","source":["r = random.randint(0, len(x_test) - 1)\n","print(\"Label:\", y_test[r])\n","print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: x_test[r].reshape(1, -1)}))\n","plt.imshow(x_test[r], cmap=\"hot\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"id":"dvkPDF8l-eLT","executionInfo":{"status":"ok","timestamp":1700035524245,"user_tz":-420,"elapsed":21,"user":{"displayName":"Dũng Hạ","userId":"13687423286186296603"}},"outputId":"81002fb2-c355-4ad1-e55d-667e3b55c0d8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Label: 0\n","Prediction: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}